Machine learning: is a field of study that focuses on computer systems that can learn from data.
That is, these systems, often called models,can learn to perform a specific task
by analyzing lots of examples for a particular problem.

Eg:identify a cat after analysisng lots of image of cats
The Machine Learning algorithm is programmed to learn from the data that 
there's nothing in the algorithm or program which directly aims to learn the given task.
** i.e Machine Learning models are not given the step by step instructions on how to recognize
the image of a cat.Instead, the model learns on its own what features
are important in determining that a picture contains a cat from the data that it has analyzed.

*Because the model learns to perform this task from data,it's good to note that the amount and quality of data
available for building the model are important factors in how well the model learns from the task.

Therefore,Machine Learning models learn from data to perform a task
without being explicitly programmed.

Clasification:
In classification,the goal is to predict the category of the input data.
The categories to be predicted are called classifications.
Eg:predicting the weather as being sunny,rainy, windy or cloudy.
If the predicted output is b/w 2 values ==> it is called binary Classification.

Regression:
When your model has to predict a numeric value instead of a category,
then the task becomes a regression problem.
Eg:predict the price of a stock.
The stock price is a numeric value,not a category, so this is a regression task.
If you were to predict whether the stock price will rise or fall,then that would 
be a classification problem but if you're predicting the actual price of the stock,
then that's a regression problem.

To summarize,in classification you're predicting a category,
and in regression,you're predicting a numeric value.

Clustering:
In cluster analysis,the goal is to organize similar items in your dataset into groups.
A very common application of cluster analysis is referred to as customer segmentation.
This means that you're separating your customer base into different groups or segments
based on customer types.
For example,
it would be beneficial to segment your customers into seniors, adults and teenagers.

association analysis:
The goal here is to come up with a set of rules
to capture associations between items or events.
The rules are used to determine when items or events occur together.
A common application of association analysis is known as market basket analysis,
which is used to understand customer purchasing behavior.
For example,
->association analysis can reveal that banking customers
who have checking or deposit accounts also tend to be interested 
in other investment vehicles such as money market accounts.
->Other common applications can be recommendation of similar items
based on purchasing or browsing history of customers.
->Identification of web pages that are often accessed together
can also provide us a good basis for association analysis.

For the techniques we've discussed here,there are two ways of conducting 
the learning itself.These categories are referred to as 
A)supervised Learning and B)unsupervised Learning

In supervised approaches,(Target is available)
the target, which is what the model is predicting,is provided.
This is referred to as having labeled data because the target is 
labeled for every sample that you have in your dataset.
Referring back to our example of predicting the weather category
of sunny, windy, rainy or cloudy,every sample in the dataset
is labeled as being one of these four categories.
So, the data is labeled and predicting the weather category is a supervised task.
**In general,classification and regression are supervised approaches.

In unsupervised approaches,(Target is not available)
on the other hand,the target that the model is predicting
is unknown or unavailable.This means that you have unlabeled data,
so you can't train using these labels.Going back to our cluster 
analysis example of segment customers into different groups,the samples
in your data are not labeled with the correct group.
Instead, the segmentation is performed using a clustering technique
to group items based on characteristics of what they have in common.
Thus, the data is unlabeled and the task of grouping customers
into different segments is an unsupervised one.
**In general, cluster analysis and association analysis are unsupervised approaches.

Terminology in ML:
Sample:
It is an instance/example of an entity in your data.It is typically a row in your dataset.

ID    Name     mat     phy 
1     A1        11      20
2     A2        14      28
3     A3        18      22

==> row's with ID's 1,2,3 are called Samples
and coloumns(ID,Name,Mat and Phy) are called Variables/features of sample.
and Each sample has 4 values(variables) associated with it.
We call these different values as variables of the sample
and sometimes refer to them as features of the sample.
A variable captures specific characteristics of each entity.

There are many names for variables in addition to feature.
like: feature, column,dimension, attribute and field etc.

A variable holding Numerical values is called as Numerical/quantitative variable.
A variable holding characters/strings ar called as categorial/nominal/qualitative variable.

Scikit-learn: 
->An open source ML library in Python
->It is built on top of NumPy, SciPy, and matplotlib like many other Python libraries.
->It can be used for end to end Machine Learning in python.
i.e entire data science process including Machine Learning,
data cleaning, and data transformations,.etc can be done by scikit-learn.

Scikit Learn Provides fns for preprocessing such as:
->fns for converting raw feature vectors into suitable formats
-> it providea API's for
  ->scaling of features: remove mean and keep unit variance
  ->Normalization to have unit form
  ->binarization to turn data into 0 or 1 form
  ->One hot encoding for categorial features
  ->handlin of missing values
  ->generating higher order features
  ->built custom transformations
Scikit-learn also provides built-in functions for many
Machine Learning algorithms ready for modeling and analysis.
Although it requires some expertise to use these algorithms
appropriately for the right tasks, there are many resources
online that make the learning curve easier.
Additionally the documentation on the website for
Scikit-learn includes tutorials to get started.
We find those documentation really easy to follow.
For example, the clustering part of the documentation
nicely overviews the available algorithms, their metrics,
scalability, parameters and even potential use cases.
Scikit-learn also includes specialized implementations
for dimensionality reduction algorithms.

Dimentionality Reduction:
->Enables you to reduce featureswhile preserving variance.
->scikit-learn has capabilities for:
  ->principal component Analysis(PCA)
  ->singular value decomposition
  ->Factor Analysis
  ->Independent Component Analysis
  ->Matrix factorization
  ->Latent Dirichled allocation(LDA)

Classification:
----------------
In a classification problem, the input data is presented to the machine learning model,
and the task is to predict the target corresponding to the input data.
The target is a categorical variable. So the classification task is to predict
the category or label of the target given the input data.
Eg: we have to predict weather b/w windy,sunny,rainy
==> Since a target is provided, we have label data,
and so classification is a supervised task.Recall that in a supervised task, the target,
or design output for each sample is given.Note that the target variable goes by many names
such as target, label, output,class variable, category, and class.
A classification problem can be binary,or multi-class.
With the binary classification, the target variable has two possible values, for example yes and no.
With multi-class classification, the target variable has more than two possible values, for example
the target can be short, medium, and tall.
Multi-class classification is also referred to as multinomial or multi-label classification.
Note:
1)Remember,the target is always a categorical variable in classification.
2)The target is provided for each sample,classification is a supervised task.

**In building a model, we need to adjust the parameters in order to reduce the model's error.
==> we need to form decision boundaries.
In the case of supervised tasks, such as classification,
this means getting the model's outputs to match the targets,
or desired outputs, as much as possible.

Building a classification model then means using the data
to adjust a model's parameters in order to form decision
boundaries to separate the target classes.(eg: in a graph we can say that all the 
elements falling in area 1 are squares,area 2 are circles etc hence
the area boundries of there areas(1 and 2) are nothing but decision boundaries) 
Note that the term classifier is often used to mean classification model.
Training phase: train data + learning Algotithm = build model ==> o/p = model
Testing phase: test data +model = apply model ==> o/p result
To adjust a model's parameters, we need to apply a learning algorithm.
commonly used algorithms for building a classification model:
kNN or k-nearest neighbors(kNN stands for K-nearest Neighbors),
Decision Trees
and NaÃ¯ve Bayes.
KNN:
This technique relies on the notion that samples
with similar characteristics, that is samples with similar
values for input, likely belong to the same class.
So classification of a sample is dependent
on the target values of the neighboring points.
Decision Tree:
A Decision Tree is a classification model that uses a tree-like structure to represent multiple decision paths.
Traversing each path leads to a different way to classify an input sample.
Eg:
               |---->non mamals
warm blooded---|                  |-----> non mammals
               |---->live birth --|                    |----->Non-Mammals
                                  |----->vertebrate ---|
                                                       |----->Mammals
Naive Bayes:
NaÃ¯ve Bayes model uses a probabilistic approach to classification.
Bayes' Theorem is used to capture the relationships within the input data and the output class.
Bayes Theorem:
         P(B|A) * P(A)
P(A|B)= ---------------
            P(B)
The Bayes Theorem compares the probability of an event in the 
presence of another event.Here we see the probability of A if B is present.
An example for this is probability of having a fire if the weather is hot.
You can imagine event B depending on more than one variable,
e.g. weather is hot and windy.
